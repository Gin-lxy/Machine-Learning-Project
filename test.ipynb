{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioTransformer(nn.Module):\n",
    "    def __init__(self, mel_channels=128, mfcc_channels=20, d_model=256, nhead=8, \n",
    "                 num_layers=4, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mel_embed = nn.Linear(mel_channels, d_model)\n",
    "        self.mfcc_embed = nn.Linear(mfcc_channels, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec, mfcc):\n",
    "        mel_embedded = self.mel_embed(mel_spec.squeeze(1).transpose(1, 2))\n",
    "        mel_encoded = self.pos_encoder(mel_embedded)\n",
    "        \n",
    "        mfcc_embedded = self.mfcc_embed(mfcc.transpose(1, 2))\n",
    "        mfcc_encoded = self.pos_encoder(mfcc_embedded)\n",
    "        \n",
    "        combined = torch.cat([mel_encoded, mfcc_encoded], dim=1)\n",
    "        transformer_output = self.transformer_encoder(combined)\n",
    "        pooled = torch.mean(transformer_output, dim=1)\n",
    "        output = self.classifier(pooled)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryPredictor:\n",
    "    def __init__(self, model_path='best_model.pth'):\n",
    "        \"\"\"\n",
    "        初始化预测器\n",
    "        model_path: 训练好的模型权重路径\n",
    "        \"\"\"\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = AudioTransformer()\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def process_audio(self, audio_path, fixed_length=130):\n",
    "        \"\"\"\n",
    "        处理音频文件并提取特征\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 加载音频\n",
    "            y, sr = librosa.load(audio_path)\n",
    "            \n",
    "            # 提取Mel频谱图\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # 提取MFCC特征\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "            \n",
    "            # 统一长度处理\n",
    "            def pad_or_truncate(array, target_length):\n",
    "                current_length = array.shape[1]\n",
    "                if current_length > target_length:\n",
    "                    return array[:, :target_length]\n",
    "                else:\n",
    "                    pad_width = ((0, 0), (0, target_length - current_length))\n",
    "                    return np.pad(array, pad_width, mode='constant')\n",
    "            \n",
    "            mel_spec_db = pad_or_truncate(mel_spec_db, fixed_length)\n",
    "            mfccs = pad_or_truncate(mfccs, fixed_length)\n",
    "            \n",
    "            return {\n",
    "                'mel_spec': mel_spec_db.astype(np.float32),\n",
    "                'mfcc': mfccs.astype(np.float32)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理音频文件时出错: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def predict(self, audio_path):\n",
    "        \"\"\"\n",
    "        预测故事的真实性\n",
    "        返回: (预测结果, 置信度)\n",
    "        \"\"\"\n",
    "        # 处理音频\n",
    "        features = self.process_audio(audio_path)\n",
    "        if features is None:\n",
    "            return None, None\n",
    "        \n",
    "        # 准备数据\n",
    "        mel_spec = torch.FloatTensor(features['mel_spec']).unsqueeze(0).unsqueeze(0)\n",
    "        mfcc = torch.FloatTensor(features['mfcc']).unsqueeze(0)\n",
    "        \n",
    "        # 移动数据到设备\n",
    "        mel_spec = mel_spec.to(self.device)\n",
    "        mfcc = mfcc.to(self.device)\n",
    "        \n",
    "        # 预测\n",
    "        with torch.no_grad():\n",
    "            output = self.model(mel_spec, mfcc)\n",
    "            probability = output.item()\n",
    "            prediction = probability > 0.5\n",
    "        \n",
    "        return prediction, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(predictor, audio_files):\n",
    "    \"\"\"\n",
    "    批量预测多个音频文件\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for audio_file in audio_files:\n",
    "        prediction, confidence = predictor.predict(audio_file)\n",
    "        results.append({\n",
    "            'file': audio_file,\n",
    "            'prediction': '真实' if prediction else '虚假',\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 初始化预测器\n",
    "    predictor = StoryPredictor('best_model.pth')\n",
    "    \n",
    "    # 单个文件预测\n",
    "    audio_path = \"00003.wav\"  # 替换为你的音频文件路径\n",
    "    prediction, confidence = predictor.predict(audio_path)\n",
    "    \n",
    "    if prediction is not None:\n",
    "        result = \"真实\" if prediction else \"虚假\"\n",
    "        print(f\"音频文件: {audio_path}\")\n",
    "        print(f\"预测结果: 这个故事很可能是{result}的\")\n",
    "        print(f\"置信度: {confidence:.2%}\")\n",
    "    \n",
    "    # 批量预测\n",
    "    audio_files = [\n",
    "        \"00004.wav\",\n",
    "        \"00005.wav\",\n",
    "        \"00003.wav\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n批量预测结果:\")\n",
    "    results = predict_batch(predictor, audio_files)\n",
    "    for result in results:\n",
    "        print(f\"\\n文件: {result['file']}\")\n",
    "        print(f\"预测结果: {result['prediction']}\")\n",
    "        print(f\"置信度: {result['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:720: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "音频文件: 00003.wav\n",
      "预测结果: 这个故事很可能是虚假的\n",
      "置信度: 49.87%\n",
      "\n",
      "批量预测结果:\n",
      "\n",
      "文件: 00004.wav\n",
      "预测结果: 真实\n",
      "置信度: 79.65%\n",
      "\n",
      "文件: 00005.wav\n",
      "预测结果: 虚假\n",
      "置信度: 38.20%\n",
      "\n",
      "文件: 00003.wav\n",
      "预测结果: 虚假\n",
      "置信度: 49.87%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
